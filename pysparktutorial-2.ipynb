{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPHJVTTKtLNHj2b+izSWEiV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":891},"id":"i567cBViAS2x","executionInfo":{"status":"ok","timestamp":1719799178229,"user_tz":-330,"elapsed":96784,"user":{"displayName":"Raghavendraswamy kambhampati","userId":"01177534085165620346"}},"outputId":"7d29a26c-c9db-4eea-8d39-cc6bf97accfb"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Waiting for headers] [W\u001b[0m\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n","Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Get:8 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,115 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n","Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,398 kB]\n","Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,976 kB]\n","Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,566 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,639 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,238 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [32.2 kB]\n","Fetched 12.4 MB in 2s (5,633 kB/s)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","47 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","tar: spark-3.2.1-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n","tar: Error is not recoverable: exiting now\n","Collecting pyspark\n","  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=1828c4820451bb6883f52b7e3fbf0af67a56d3f9aded40772ebbe654c9f66ba9\n","  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.5.1\n","Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"]},{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7ad21611f6a0>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://4e5ecfda7ff8:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.5.1</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Our First Spark Example</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":2}],"source":["!sudo apt update\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","#Check this site for the latest download link https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n","!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n","!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n","!pip install -q findspark\n","!pip install pyspark\n","!pip install py4j\n","\n","import os\n","import sys\n","# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n","\n","\n","import findspark\n","findspark.init()\n","findspark.find()\n","\n","import pyspark\n","\n","from pyspark.sql import DataFrame, SparkSession\n","from typing import List\n","import pyspark.sql.types as T\n","import pyspark.sql.functions as F\n","\n","spark= SparkSession.builder.appName(\"Our First Spark Example\").getOrCreate()\n","\n","spark"]},{"cell_type":"code","source":["import pyspark\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import approx_count_distinct,collect_list\n","from pyspark.sql.functions import collect_set,sum,avg,max,countDistinct,count\n","from pyspark.sql.functions import first, last, kurtosis, min, mean, skewness\n","from pyspark.sql.functions import stddev, stddev_samp, stddev_pop, sumDistinct\n","from pyspark.sql.functions import variance,var_samp,  var_pop\n","\n","spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n","\n","simpleData = [(\"James\", \"Sales\", 3000),\n","    (\"Michael\", \"Sales\", 4600),\n","    (\"Robert\", \"Sales\", 4100),\n","    (\"Maria\", \"Finance\", 3000),\n","    (\"James\", \"Sales\", 3000),\n","    (\"Scott\", \"Finance\", 3300),\n","    (\"Jen\", \"Finance\", 3900),\n","    (\"Jeff\", \"Marketing\", 3000),\n","    (\"Kumar\", \"Marketing\", 2000),\n","    (\"Saif\", \"Sales\", 4100)\n","  ]\n","schema = [\"employee_name\", \"department\", \"salary\"]\n","\n","\n","df = spark.createDataFrame(data=simpleData, schema = schema)\n","df.printSchema()\n","df.show(truncate=False)\n","\n","print(\"approx_count_distinct: \" + \\\n","      str(df.select(approx_count_distinct(\"salary\")).collect()[0][0]))\n","\n","print(\"avg: \" + str(df.select(avg(\"salary\")).collect()[0][0]))\n","\n","df.select(collect_list(\"salary\")).show(truncate=False)\n","\n","df.select(collect_set(\"salary\")).show(truncate=False)\n","\n","df2 = df.select(countDistinct(\"department\", \"salary\"))\n","df2.show(truncate=False)\n","print(\"Distinct Count of Department &amp; Salary: \"+str(df2.collect()[0][0]))\n","\n","print(\"count: \"+str(df.select(count(\"salary\")).collect()[0]))\n","df.select(first(\"salary\")).show(truncate=False)\n","df.select(last(\"salary\")).show(truncate=False)\n","df.select(kurtosis(\"salary\")).show(truncate=False)\n","df.select(max(\"salary\")).show(truncate=False)\n","df.select(min(\"salary\")).show(truncate=False)\n","df.select(mean(\"salary\")).show(truncate=False)\n","df.select(skewness(\"salary\")).show(truncate=False)\n","df.select(stddev(\"salary\"), stddev_samp(\"salary\"), \\\n","    stddev_pop(\"salary\")).show(truncate=False)\n","df.select(sum(\"salary\")).show(truncate=False)\n","df.select(sumDistinct(\"salary\")).show(truncate=False)\n","df.select(variance(\"salary\"),var_samp(\"salary\"),var_pop(\"salary\")) \\\n","  .show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H-on7B1UAayr","executionInfo":{"status":"ok","timestamp":1719799239231,"user_tz":-330,"elapsed":27479,"user":{"displayName":"Raghavendraswamy kambhampati","userId":"01177534085165620346"}},"outputId":"b812735b-c317-4666-fcc8-cf3f92a5ef31"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- employee_name: string (nullable = true)\n"," |-- department: string (nullable = true)\n"," |-- salary: long (nullable = true)\n","\n","+-------------+----------+------+\n","|employee_name|department|salary|\n","+-------------+----------+------+\n","|James        |Sales     |3000  |\n","|Michael      |Sales     |4600  |\n","|Robert       |Sales     |4100  |\n","|Maria        |Finance   |3000  |\n","|James        |Sales     |3000  |\n","|Scott        |Finance   |3300  |\n","|Jen          |Finance   |3900  |\n","|Jeff         |Marketing |3000  |\n","|Kumar        |Marketing |2000  |\n","|Saif         |Sales     |4100  |\n","+-------------+----------+------+\n","\n","approx_count_distinct: 6\n","avg: 3400.0\n","+------------------------------------------------------------+\n","|collect_list(salary)                                        |\n","+------------------------------------------------------------+\n","|[3000, 4600, 4100, 3000, 3000, 3300, 3900, 3000, 2000, 4100]|\n","+------------------------------------------------------------+\n","\n","+------------------------------------+\n","|collect_set(salary)                 |\n","+------------------------------------+\n","|[4600, 3000, 3900, 4100, 3300, 2000]|\n","+------------------------------------+\n","\n","+----------------------------------+\n","|count(DISTINCT department, salary)|\n","+----------------------------------+\n","|8                                 |\n","+----------------------------------+\n","\n","Distinct Count of Department &amp; Salary: 8\n","count: Row(count(salary)=10)\n","+-------------+\n","|first(salary)|\n","+-------------+\n","|3000         |\n","+-------------+\n","\n","+------------+\n","|last(salary)|\n","+------------+\n","|4100        |\n","+------------+\n","\n","+-------------------+\n","|kurtosis(salary)   |\n","+-------------------+\n","|-0.6467803030303032|\n","+-------------------+\n","\n","+-----------+\n","|max(salary)|\n","+-----------+\n","|4600       |\n","+-----------+\n","\n","+-----------+\n","|min(salary)|\n","+-----------+\n","|2000       |\n","+-----------+\n","\n","+-----------+\n","|avg(salary)|\n","+-----------+\n","|3400.0     |\n","+-----------+\n","\n","+--------------------+\n","|skewness(salary)    |\n","+--------------------+\n","|-0.12041791181069571|\n","+--------------------+\n","\n","+-----------------+-------------------+------------------+\n","|stddev(salary)   |stddev_samp(salary)|stddev_pop(salary)|\n","+-----------------+-------------------+------------------+\n","|765.9416862050705|765.9416862050705  |726.636084983398  |\n","+-----------------+-------------------+------------------+\n","\n","+-----------+\n","|sum(salary)|\n","+-----------+\n","|34000      |\n","+-----------+\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pyspark/sql/functions.py:988: FutureWarning: Deprecated in 3.2, use sum_distinct instead.\n","  warnings.warn(\"Deprecated in 3.2, use sum_distinct instead.\", FutureWarning)\n"]},{"output_type":"stream","name":"stdout","text":["+--------------------+\n","|sum(DISTINCT salary)|\n","+--------------------+\n","|20900               |\n","+--------------------+\n","\n","+-----------------+-----------------+---------------+\n","|var_samp(salary) |var_samp(salary) |var_pop(salary)|\n","+-----------------+-----------------+---------------+\n","|586666.6666666666|586666.6666666666|528000.0       |\n","+-----------------+-----------------+---------------+\n","\n"]}]},{"cell_type":"code","source":["from pyspark.sql import SparkSession,Row\n","spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n","\n","data=[(\"James\",23),(\"Ann\",40)]\n","df=spark.createDataFrame(data).toDF(\"name.fname\",\"gender\")\n","df.printSchema()\n","df.show()\n","\n","from pyspark.sql.functions import col\n","df.select(col(\"`name.fname`\")).show()\n","df.select(df[\"`name.fname`\"]).show()\n","df.withColumn(\"new_col\",col(\"`name.fname`\").substr(1,2)).show()\n","df.filter(col(\"`name.fname`\").startswith(\"J\")).show()\n","new_cols=(column.replace('.', '_') for column in df.columns)\n","df2 = df.toDF(*new_cols)\n","df2.show()\n","\n","\n","# Using DataFrame object\n","df.select(df.gender).show()\n","df.select(df[\"gender\"]).show()\n","#Accessing column name with dot (with backticks)\n","df.select(df[\"`name.fname`\"]).show()\n","\n","#Using SQL col() function\n","from pyspark.sql.functions import col\n","df.select(col(\"gender\")).show()\n","#Accessing column name with dot (with backticks)\n","df.select(col(\"`name.fname`\")).show()\n","\n","#Access struct column\n","data=[Row(name=\"James\",prop=Row(hair=\"black\",eye=\"blue\")),\n","      Row(name=\"Ann\",prop=Row(hair=\"grey\",eye=\"black\"))]\n","df=spark.createDataFrame(data)\n","df.printSchema()\n","\n","df.select(df.prop.hair).show()\n","df.select(df[\"prop.hair\"]).show()\n","df.select(col(\"prop.hair\")).show()\n","df.select(col(\"prop.*\")).show()\n","\n","# Column operators\n","data=[(100,2,1),(200,3,4),(300,4,4)]\n","df=spark.createDataFrame(data).toDF(\"col1\",\"col2\",\"col3\")\n","df.select(df.col1 + df.col2).show()\n","df.select(df.col1 - df.col2).show()\n","df.select(df.col1 * df.col2).show()\n","df.select(df.col1 / df.col2).show()\n","df.select(df.col1 % df.col2).show()\n","\n","df.select(df.col2 > df.col3).show()\n","df.select(df.col2 < df.col3).show()\n","df.select(df.col2 == df.col3).show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pnSPQvJeAa_B","executionInfo":{"status":"ok","timestamp":1719800216777,"user_tz":-330,"elapsed":14604,"user":{"displayName":"Raghavendraswamy kambhampati","userId":"01177534085165620346"}},"outputId":"dac89a01-cf70-4cf7-ee47-9c7b3d995b9b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- name.fname: string (nullable = true)\n"," |-- gender: long (nullable = true)\n","\n","+----------+------+\n","|name.fname|gender|\n","+----------+------+\n","|     James|    23|\n","|       Ann|    40|\n","+----------+------+\n","\n","+----------+\n","|name.fname|\n","+----------+\n","|     James|\n","|       Ann|\n","+----------+\n","\n","+----------+\n","|name.fname|\n","+----------+\n","|     James|\n","|       Ann|\n","+----------+\n","\n","+----------+------+-------+\n","|name.fname|gender|new_col|\n","+----------+------+-------+\n","|     James|    23|     Ja|\n","|       Ann|    40|     An|\n","+----------+------+-------+\n","\n","+----------+------+\n","|name.fname|gender|\n","+----------+------+\n","|     James|    23|\n","+----------+------+\n","\n","+----------+------+\n","|name_fname|gender|\n","+----------+------+\n","|     James|    23|\n","|       Ann|    40|\n","+----------+------+\n","\n","+------+\n","|gender|\n","+------+\n","|    23|\n","|    40|\n","+------+\n","\n","+------+\n","|gender|\n","+------+\n","|    23|\n","|    40|\n","+------+\n","\n","+----------+\n","|name.fname|\n","+----------+\n","|     James|\n","|       Ann|\n","+----------+\n","\n","+------+\n","|gender|\n","+------+\n","|    23|\n","|    40|\n","+------+\n","\n","+----------+\n","|name.fname|\n","+----------+\n","|     James|\n","|       Ann|\n","+----------+\n","\n","root\n"," |-- name: string (nullable = true)\n"," |-- prop: struct (nullable = true)\n"," |    |-- hair: string (nullable = true)\n"," |    |-- eye: string (nullable = true)\n","\n","+---------+\n","|prop.hair|\n","+---------+\n","|    black|\n","|     grey|\n","+---------+\n","\n","+-----+\n","| hair|\n","+-----+\n","|black|\n","| grey|\n","+-----+\n","\n","+-----+\n","| hair|\n","+-----+\n","|black|\n","| grey|\n","+-----+\n","\n","+-----+-----+\n","| hair|  eye|\n","+-----+-----+\n","|black| blue|\n","| grey|black|\n","+-----+-----+\n","\n","+-------------+\n","|(col1 + col2)|\n","+-------------+\n","|          102|\n","|          203|\n","|          304|\n","+-------------+\n","\n","+-------------+\n","|(col1 - col2)|\n","+-------------+\n","|           98|\n","|          197|\n","|          296|\n","+-------------+\n","\n","+-------------+\n","|(col1 * col2)|\n","+-------------+\n","|          200|\n","|          600|\n","|         1200|\n","+-------------+\n","\n","+-----------------+\n","|    (col1 / col2)|\n","+-----------------+\n","|             50.0|\n","|66.66666666666667|\n","|             75.0|\n","+-----------------+\n","\n","+-------------+\n","|(col1 % col2)|\n","+-------------+\n","|            0|\n","|            2|\n","|            0|\n","+-------------+\n","\n","+-------------+\n","|(col2 > col3)|\n","+-------------+\n","|         true|\n","|        false|\n","|        false|\n","+-------------+\n","\n","+-------------+\n","|(col2 < col3)|\n","+-------------+\n","|        false|\n","|         true|\n","|        false|\n","+-------------+\n","\n","+-------------+\n","|(col2 = col3)|\n","+-------------+\n","|        false|\n","|        false|\n","|         true|\n","+-------------+\n","\n"]}]},{"cell_type":"code","source":["data = [(\"James\", \"Sales\", 3000),\n","    (\"Michael\", \"Sales\", 4600),\n","    (\"Robert\", \"Sales\", 4100),\n","    (\"Maria\", \"Finance\", 3000),\n","    (\"James\", \"Sales\", 3000),\n","    (\"Scott\", \"Finance\", 3300),\n","    (\"Jen\", \"Finance\", 3900),\n","    (\"Jeff\", \"Marketing\", 3000),\n","    (\"Kumar\", \"Marketing\", 2000),\n","    (\"Saif\", \"Sales\", 4100)\n","  ]\n","columns = [\"Name\",\"Dept\",\"Salary\"]\n","df = spark.createDataFrame(data=data,schema=columns)\n","df.distinct().show()\n","print(\"Distinct Count: \" + str(df.distinct().count()))\n","\n","# Using countDistrinct()\n","from pyspark.sql.functions import countDistinct\n","df2=df.select(countDistinct(\"Dept\",\"Salary\"))\n","df2.show()\n","\n","print(\"Distinct Count of Department &amp; Salary: \"+ str(df2.collect()[0][0]))\n","\n","df.createOrReplaceTempView(\"PERSON\")\n","spark.sql(\"select distinct(count(*)) from PERSON\").show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TZ7NsggVAbJ2","executionInfo":{"status":"ok","timestamp":1719800591208,"user_tz":-330,"elapsed":4923,"user":{"displayName":"Raghavendraswamy kambhampati","userId":"01177534085165620346"}},"outputId":"308812b0-8eb1-4158-f6b0-ecb18f0e07a5"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+---------+------+\n","|   Name|     Dept|Salary|\n","+-------+---------+------+\n","|Michael|    Sales|  4600|\n","|  James|    Sales|  3000|\n","| Robert|    Sales|  4100|\n","|  Maria|  Finance|  3000|\n","|    Jen|  Finance|  3900|\n","|  Scott|  Finance|  3300|\n","|  Kumar|Marketing|  2000|\n","|   Jeff|Marketing|  3000|\n","|   Saif|    Sales|  4100|\n","+-------+---------+------+\n","\n","Distinct Count: 9\n","+----------------------------+\n","|count(DISTINCT Dept, Salary)|\n","+----------------------------+\n","|                           8|\n","+----------------------------+\n","\n","Distinct Count of Department &amp; Salary: 8\n","+--------+\n","|count(1)|\n","+--------+\n","|      10|\n","+--------+\n","\n"]}]},{"cell_type":"code","source":["simpleData = [(\"James\",\"Sales\",\"NY\",90000,34,10000),\n","    (\"Michael\",\"Sales\",\"NV\",86000,56,20000),\n","    (\"Robert\",\"Sales\",\"CA\",81000,30,23000),\n","    (\"Maria\",\"Finance\",\"CA\",90000,24,23000),\n","    (\"Raman\",\"Finance\",\"DE\",99000,40,24000),\n","    (\"Scott\",\"Finance\",\"NY\",83000,36,19000),\n","    (\"Jen\",\"Finance\",\"NY\",79000,53,15000),\n","    (\"Jeff\",\"Marketing\",\"NV\",80000,25,18000),\n","    (\"Kumar\",\"Marketing\",\"NJ\",91000,50,21000)\n","  ]\n","\n","schema = [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n","df = spark.createDataFrame(data=simpleData, schema = schema)\n","df.printSchema()\n","df.show(truncate=False)\n","\n","df.groupBy(\"state\").sum(\"salary\").show()\n","\n","dfGroup=df.groupBy(\"state\") \\\n","          .agg(sum(\"salary\").alias(\"sum_salary\"))\n","\n","dfGroup.show(truncate=False)\n","\n","dfFilter=dfGroup.filter(dfGroup.sum_salary > 100000)\n","dfFilter.show()\n","\n","from pyspark.sql.functions import asc\n","dfFilter.sort(\"sum_salary\").show()\n","\n","from pyspark.sql.functions import desc\n","dfFilter.sort(desc(\"sum_salary\")).show()\n","\n","df.groupBy(\"state\") \\\n","  .agg(sum(\"salary\").alias(\"sum_salary\")) \\\n","  .filter(col(\"sum_salary\") > 100000)  \\\n","  .sort(desc(\"sum_salary\")) \\\n","  .show()\n","\n","df.createOrReplaceTempView(\"EMP\")\n","spark.sql(\"select state, sum(salary) as sum_salary from EMP \" +\n","          \"group by state having sum_salary > 100000 \" +\n","          \"order by sum_salary desc\").show()\n","\n","df.groupBy(\"state\") \\\n","  .sum(\"salary\") \\\n","  .withColumnRenamed(\"sum(salary)\", \"sum_salary\") \\\n","  .show()\n","\n","df.groupBy(\"state\") \\\n","  .sum(\"salary\") \\\n","  .select(col(\"state\"),col(\"sum(salary)\").alias(\"sum_salary\")) \\\n","  .show()\n",""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hM7TELZJGtHd","executionInfo":{"status":"ok","timestamp":1719800789804,"user_tz":-330,"elapsed":6809,"user":{"displayName":"Raghavendraswamy kambhampati","userId":"01177534085165620346"}},"outputId":"cb2c09d0-5d58-4df2-adb0-b58a3bec8db7"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- employee_name: string (nullable = true)\n"," |-- department: string (nullable = true)\n"," |-- state: string (nullable = true)\n"," |-- salary: long (nullable = true)\n"," |-- age: long (nullable = true)\n"," |-- bonus: long (nullable = true)\n","\n","+-------------+----------+-----+------+---+-----+\n","|employee_name|department|state|salary|age|bonus|\n","+-------------+----------+-----+------+---+-----+\n","|James        |Sales     |NY   |90000 |34 |10000|\n","|Michael      |Sales     |NV   |86000 |56 |20000|\n","|Robert       |Sales     |CA   |81000 |30 |23000|\n","|Maria        |Finance   |CA   |90000 |24 |23000|\n","|Raman        |Finance   |DE   |99000 |40 |24000|\n","|Scott        |Finance   |NY   |83000 |36 |19000|\n","|Jen          |Finance   |NY   |79000 |53 |15000|\n","|Jeff         |Marketing |NV   |80000 |25 |18000|\n","|Kumar        |Marketing |NJ   |91000 |50 |21000|\n","+-------------+----------+-----+------+---+-----+\n","\n","+-----+-----------+\n","|state|sum(salary)|\n","+-----+-----------+\n","|   NV|     166000|\n","|   CA|     171000|\n","|   NY|     252000|\n","|   NJ|      91000|\n","|   DE|      99000|\n","+-----+-----------+\n","\n","+-----+----------+\n","|state|sum_salary|\n","+-----+----------+\n","|NV   |166000    |\n","|CA   |171000    |\n","|NY   |252000    |\n","|NJ   |91000     |\n","|DE   |99000     |\n","+-----+----------+\n","\n","+-----+----------+\n","|state|sum_salary|\n","+-----+----------+\n","|   NV|    166000|\n","|   CA|    171000|\n","|   NY|    252000|\n","+-----+----------+\n","\n","+-----+----------+\n","|state|sum_salary|\n","+-----+----------+\n","|   NV|    166000|\n","|   CA|    171000|\n","|   NY|    252000|\n","+-----+----------+\n","\n","+-----+----------+\n","|state|sum_salary|\n","+-----+----------+\n","|   NY|    252000|\n","|   CA|    171000|\n","|   NV|    166000|\n","+-----+----------+\n","\n","+-----+----------+\n","|state|sum_salary|\n","+-----+----------+\n","|   NY|    252000|\n","|   CA|    171000|\n","|   NV|    166000|\n","+-----+----------+\n","\n","+-----+----------+\n","|state|sum_salary|\n","+-----+----------+\n","|   NY|    252000|\n","|   CA|    171000|\n","|   NV|    166000|\n","+-----+----------+\n","\n","+-----+----------+\n","|state|sum_salary|\n","+-----+----------+\n","|   NV|    166000|\n","|   CA|    171000|\n","|   NY|    252000|\n","|   NJ|     91000|\n","|   DE|     99000|\n","+-----+----------+\n","\n","+-----+----------+\n","|state|sum_salary|\n","+-----+----------+\n","|   NV|    166000|\n","|   CA|    171000|\n","|   NY|    252000|\n","|   NJ|     91000|\n","|   DE|     99000|\n","+-----+----------+\n","\n"]}]}]}